{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Ridge Regression on Garibaldi, train on GTEx, test on MDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scp, you will be able to transfer files between garibaldi and pejlab server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels\n",
    "from scipy import stats\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "# Import nn.functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the gene labels ENSGXXXX.1  -> ENSGXXXX\n",
    "def trimLabelss(names):\n",
    "    return [i.split(\".\")[0] for i in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Gene names into different subfiles 100 genes in 1 file  (run 100 models in 1 job)\n",
    "ind = sys.argv[1]\n",
    "# Read in genes interested\n",
    "diagnosedIDs = list(pd.read_csv(\"/gpfs/home/ydong/data/GTEx/GTExProteinGenes/\"+ind+\".txt\",header = None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare output file/folder\n",
    "if not os.path.exists(\"/gpfs/home/ydong/data/mini/models/\"+ind):\n",
    "    os.mkdir(\"/gpfs/home/ydong/data/mini/models/\"+ind) \n",
    "    \n",
    "resF = open(\"/gpfs/home/ydong/data/mini/res/\"+ind+\".csv\", 'a')\n",
    "header = [\"gene\",\"train_R2\",\"val_R2\",\"loss\",\"time\"]\n",
    "resF.write(\",\".join(header))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import GTEx gene count matrix\n",
    "normedMat = pd.read_csv(\"/gpfs/home/ydong/data/logTrimmedNormedCounts.csv\",index_col = \"Name\")\n",
    "\n",
    "normedMat = normedMat.transpose()\n",
    "\n",
    "#trim gene labels ENSGXXXX.1  -> ENSGXXXX\n",
    "normedMat.columns = trimLabelss(normedMat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for pseudo random\n",
    "random.seed(123)\n",
    "\n",
    "# randomly split training and validation set\n",
    "samples = range(len(normedMat.index))\n",
    "trainInd = random.sample(samples, 13913)\n",
    "\n",
    "# Return the unique values in ar1 that are not in ar2.\n",
    "valInd = np.setdiff1d(samples,trainInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "curr1 = time.time()\n",
    "\n",
    "# initialize parameters (these turned out to be optimal parameters after testing)\n",
    "#l2Param is the alpha /normalization coefficient value for l2 normaliztion (Ridge Regression))\n",
    "l2Param = 1e-5\n",
    "learningRate = 1e-7\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "for currID in diagnosedIDs:  \n",
    "\n",
    "    # grab training data\n",
    "    x_train, y_train = normedMat.drop(currID,axis = 1).iloc[trainInd,:].to_numpy(), np.reshape(normedMat[currID].iloc[trainInd].to_numpy(), (len(trainInd),1))\n",
    "\n",
    "    x_val, y_val = normedMat.drop(currID,axis = 1).iloc[valInd,:].to_numpy(), np.reshape(normedMat[currID].iloc[valInd].to_numpy(), (len(valInd),1))\n",
    "\n",
    "    # create tensor variables\n",
    "    x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "    y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "    x_val_tensor = torch.from_numpy(x_val).float().to(device)\n",
    "    y_val_tensor = torch.from_numpy(y_val).float().to(device)\n",
    "\n",
    "    train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    val_data = TensorDataset(x_val_tensor,y_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "    model = nn.Linear(in_features =18848 , out_features = 1)\n",
    "    #Define loss function\n",
    "    loss_fn = F.mse_loss\n",
    "    LOSS = []\n",
    "\n",
    "    #Define optimizer\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=learningRate,weight_decay = l2Param)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # minibatch\n",
    "        for i, data in enumerate(train_loader, 0):    \n",
    "\n",
    "            xb,yb = data\n",
    "            # initialize optimizer\n",
    "            opt.zero_grad()         \n",
    "\n",
    "            #Generate predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred,yb)\n",
    "\n",
    "            #Perform gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    # save current model\n",
    "    torch.save(model, \"/gpfs/home/ydong/data/mini/models/\" +ind+\"/\"+ currID + \".sav\")\n",
    "\n",
    "    \n",
    "    # record loss of current model    \n",
    "    lossEpochs = loss.item()\n",
    "\n",
    "    # R2 of current model\n",
    "    val_R2 = r2_score(model(x_val_tensor).detach().numpy(),y_val)\n",
    "    train_R2 = r2_score(model(x_train_tensor).detach().numpy(),y_train)\n",
    "\n",
    "    currRow = \",\".join( [currID,str(train_R2),str(val_R2),str(lossEpochs)])\n",
    "    resF.write(currRow)\n",
    "    \n",
    "    \n",
    "    curr2 = time.time()\n",
    "    print(currID + \": \" )\n",
    "    print(curr2 - curr1)\n",
    "    curr1 = curr2\n",
    "\n",
    "end = time.time()\n",
    "print(\"total time:\")\n",
    "print(end - start)\n",
    "resF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
